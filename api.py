# api.py

import os
from dotenv import load_dotenv
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from pydantic import BaseModel

from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain.chains.retrieval import create_retrieval_chain

# ğŸ” Chargement de la clÃ© OpenAI depuis le fichier .env
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    raise ValueError("âŒ ClÃ© API OpenAI manquante. VÃ©rifie ton fichier .env.")

# ğŸš€ Initialisation de l'application FastAPI
app = FastAPI()

# ğŸŒ Autoriser les appels depuis le frontend local + Render
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:5500",
        "http://127.0.0.1:5500",
        "https://chatbot-o4gm.onrender.com",
        "https://lastation-prod.com"
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ğŸ“¦ Chargement de l'index FAISS
print("ğŸ”„ Chargement de l'index FAISS...")
vectorstore = FAISS.load_local(
    "faiss_index",
    OpenAIEmbeddings(openai_api_key=openai_api_key),
    allow_dangerous_deserialization=True
)
retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 3})
print("âœ… Index chargÃ©.")

# ğŸ’¬ Prompt Markdown-friendly
prompt_template = PromptTemplate(
    input_variables=["context", "input"],
    template="""
Tu es un assistant expert en vidÃ©o travaillant pour l'agence "La Station".

RÃ©ponds de maniÃ¨re concise, professionnelle et directe. Limite ta rÃ©ponse Ã  l'essentiel.


Utilise uniquement les informations suivantes :
{context}

Question : {input}

RÃ©ponse (avec du **gras Markdown** pour les points clÃ©s) :
"""
)

# ğŸ¤– LLM et chaÃ®ne RAG
llm = ChatOpenAI(openai_api_key=openai_api_key, temperature=0.3)
qa_chain = create_retrieval_chain(retriever, prompt_template | llm)

# ğŸ“¥ Format attendu pour les requÃªtes entrantes
class Question(BaseModel):
    query: str

# ğŸ” Endpoint principal du chatbot
@app.post("/ask")
async def ask_question(question: Question):
    print(f"ğŸ§  Question reÃ§ue : {question.query}")
    
    response = qa_chain.invoke({"input": question.query})
    print("ğŸ§¾ RÃ©ponse brute :", response)

    return {
        "answer": response.get("answer") or response.get("result") or "âŒ RÃ©ponse vide",
        "sources": [doc.metadata.get("source", "inconnu") for doc in response.get("source_documents", [])]
    }

# (Optionnel) Interface HTML
app.mount("/static", StaticFiles(directory="static"), name="static")
templates = Jinja2Templates(directory="templates")

@app.get("/", response_class=HTMLResponse)
async def serve_home(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})



class CompanyInfo(BaseModel):
    nom_entreprise: str
    secteur: str
    site_web: str
    valeurs: list[str]
    localisation: str
    contact_nom: str
    contact_poste: str

@app.post("/generate_email")
async def generate_email(info: CompanyInfo):
    print(f"ğŸ“¨ GÃ©nÃ©ration email pour : {info.nom_entreprise}")

    user_query = f"GÃ©nÃ¨re un email de prospection pour une entreprise du secteur {info.secteur}."
    
    rag_response = qa_chain.invoke({"input": user_query})
    contexte_station = rag_response.get("context", "")

    # ğŸ§  Ajout de la logique de contact
    if info.contact_nom and info.contact_nom.lower() != "madame, monsieur":
        contact_section = f"- Contact : {info.contact_nom} ({info.contact_poste})"
        formule_intro = f"Bonjour {info.contact_nom},"
    else:
        contact_section = "- Contact : Madame, Monsieur"
        formule_intro = "Madame, Monsieur,"

    # ğŸ“¬ Prompt final
    generation_prompt = f"""
Tu es un expert en communication travaillant pour l'agence audiovisuelle "La Station Production", basÃ©e Ã  Rennes et spÃ©cialisÃ©e dans la crÃ©ation de vidÃ©os personnalisÃ©es pour les entreprises.

Voici le contexte sur notre agence :
{contexte_station}

Voici les informations sur lâ€™entreprise cible :
- Nom de lâ€™entreprise : {info.nom_entreprise}
- Secteur dâ€™activitÃ© : {info.secteur}
- Localisation : {info.localisation}
- Site web : {info.site_web}
- Valeurs principales : {", ".join(info.valeurs)}
{contact_section}

ğŸ¯ Ta mission : RÃ©dige un **email de prospection professionnel, personnalisÃ© et engageant** pour proposer les services de La Station.

Structure demandÃ©e :
1. **Objet** : accroche courte et attractive, en lien avec leur activitÃ© ou un bÃ©nÃ©fice vidÃ©o
2. **Introduction** : commence par "{formule_intro}"
3. **Corps** : 3 Ã  4 paragraphes qui suivent ce fil :
   - Observation pertinente sur leur site, communication ou secteur
   - Suggestion de types de vidÃ©os adaptÃ©es Ã  leur profil
   - Mise en avant des bÃ©nÃ©fices concrets (visibilitÃ©, image, confianceâ€¦)
4. **Conclusion** : ouverture vers une discussion + mention du site ou du dossier de presse
5. **Signature** : prÃ©nom, nom, nom de lâ€™agence, email, tÃ©lÃ©phone, site web

ğŸ§  Ligne Ã©ditoriale :
- Ton professionnel mais chaleureux
- Met en avant lâ€™expertise de La Station
- Email prÃªt Ã  Ãªtre envoyÃ©, sans phrases gÃ©nÃ©riques

âœï¸ RÃ©ponds uniquement avec lâ€™email complet, bien formatÃ© et prÃªt Ã  copier-coller.
"""


    email = llm.invoke(generation_prompt)
    return {"email": email}

